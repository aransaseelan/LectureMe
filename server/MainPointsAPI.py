import os
from openai import OpenAI
from dotenv import load_dotenv, find_dotenv

# Uncomment below for testing purposes
# def main():
#     temp_transcript = [{'text': 'yesterday the clouds opened up and a', 'start': 0.12, 'duration': 3.4}, {'text': 'weird new programming language came down', 'start': 1.92, 'duration': 3.8}, {'text': 'to earth with a promise of parallelism', 'start': 3.52, 'duration': 4.52}, {'text': 'for allou who writeth code this is big', 'start': 5.72, 'duration': 4.24}, {'text': 'if true because parallel Computing is a', 'start': 8.04, 'duration': 3.719}, {'text': 'superpower it allows a programmer to', 'start': 9.96, 'duration': 3.36}, {'text': 'take a problem that could be solved in a', 'start': 11.759, 'duration': 3.561}, {'text': 'week and instead solve it in seven days', 'start': 13.32, 'duration': 3.64}, {'text': 'using seven different computers', 'start': 15.32, 'duration': 3.56}, {'text': 'unfortunately running code in parallel', 'start': 16.96, 'duration': 3.64}, {'text': 'is like conducting a symphony one wrong', 'start': 18.88, 'duration': 3.319}, {'text': 'note and the entire thing becomes a', 'start': 20.6, 'duration': 3.88}, {'text': 'total disaster but luckily Bend offers', 'start': 22.199, 'duration': 4.441}, {'text': 'Hope by making a bold promise everything', 'start': 24.48, 'duration': 4.039}, {'text': 'that can run in parallel will run in', 'start': 26.64, 'duration': 3.44}, {'text': "parallel you don't need to know anything", 'start': 28.519, 'duration': 4.441}, {'text': 'about Cuda blocks locks mutexes or', 'start': 30.08, 'duration': 5.12}, {'text': "regex's to write algorithms that take", 'start': 32.96, 'duration': 4.84}, {'text': 'advantage of all 24 of your CPU cores or', 'start': 35.2, 'duration': 5.519}, {'text': 'even all 16,000 of your GPU cores you', 'start': 37.8, 'duration': 4.759}, {'text': 'just write some highlevel python looking', 'start': 40.719, 'duration': 3.881}, {'text': 'code and the rest is Magic it is May', 'start': 42.559, 'duration': 4.561}, {'text': "17th 2024 and you're watching the code", 'start': 44.6, 'duration': 4.0}, {'text': 'report when you write code in a language', 'start': 47.12, 'duration': 3.48}, {'text': 'like python your code runs on a single', 'start': 48.6, 'duration': 3.72}, {'text': 'thread that means only one thing can', 'start': 50.6, 'duration': 3.439}, {'text': "happen at a time it's like going to a", 'start': 52.32, 'duration': 3.68}, {'text': 'KFC with only one employee who takes the', 'start': 54.039, 'duration': 3.68}, {'text': 'order cleans the toilets and Cooks the', 'start': 56.0, 'duration': 4.12}, {'text': 'food in that order now on a modern CPU', 'start': 57.719, 'duration': 4.121}, {'text': 'you might have a clock cycle around 4', 'start': 60.12, 'duration': 3.88}, {'text': "GHz and if it's handling one instruction", 'start': 61.84, 'duration': 4.279}, {'text': "per cycle you're only able to perform 4", 'start': 64.0, 'duration': 4.0}, {'text': 'billion instructions per second now if', 'start': 66.119, 'duration': 4.801}, {'text': 'four giips is not enough you can modify', 'start': 68.0, 'duration': 4.68}, {'text': 'your python code to take advantage of', 'start': 70.92, 'duration': 3.68}, {'text': 'multiple threads but it adds a lot of', 'start': 72.68, 'duration': 3.68}, {'text': "complexity to your code and there's all", 'start': 74.6, 'duration': 4.04}, {'text': 'kinds of gotas like race conditions', 'start': 76.36, 'duration': 4.52}, {'text': 'Deadlocks thread starvation and may even', 'start': 78.64, 'duration': 4.04}, {'text': 'lead to conflicts with demons even if', 'start': 80.88, 'duration': 3.32}, {'text': 'you do manage to get it working you', 'start': 82.68, 'duration': 3.16}, {'text': "might find that your CPU just doesn't", 'start': 84.2, 'duration': 3.2}, {'text': 'have enough juice at which point you', 'start': 85.84, 'duration': 3.48}, {'text': 'look into using the thousands of cacor', 'start': 87.4, 'duration': 3.64}, {'text': "on your GPU you but now you'll need to", 'start': 89.32, 'duration': 3.88}, {'text': 'write some C++ code and likely blow your', 'start': 91.04, 'duration': 3.8}, {'text': 'leg off in the process well what if', 'start': 93.2, 'duration': 3.16}, {'text': 'there is a language that just knew how', 'start': 94.84, 'duration': 3.44}, {'text': 'to run things in parallel by default', 'start': 96.36, 'duration': 3.6}, {'text': "that's the promise of Bend imagine we", 'start': 98.28, 'duration': 3.32}, {'text': 'have a computation that adds two', 'start': 99.96, 'duration': 3.479}, {'text': 'completely random numbers together in', 'start': 101.6, 'duration': 3.28}, {'text': 'Python The Interpreter is going to', 'start': 103.439, 'duration': 2.96}, {'text': 'convert this into B code and then', 'start': 104.88, 'duration': 3.199}, {'text': 'eventually run it on the python virtual', 'start': 106.399, 'duration': 3.881}, {'text': 'machine pretty simple but in Bend things', 'start': 108.079, 'duration': 3.921}, {'text': 'are a little more complex the elements', 'start': 110.28, 'duration': 3.799}, {'text': 'of the computation are structured into a', 'start': 112.0, 'duration': 3.68}, {'text': 'graph which are called interaction', 'start': 114.079, 'duration': 3.4}, {'text': 'combinators you can think of it as a big', 'start': 115.68, 'duration': 3.32}, {'text': 'network of all the computations that', 'start': 117.479, 'duration': 3.201}, {'text': 'need to be done when two nodes run into', 'start': 119.0, 'duration': 4.039}, {'text': 'each other the computation progresses by', 'start': 120.68, 'duration': 4.039}, {'text': 'following a simple set of rules that', 'start': 123.039, 'duration': 3.44}, {'text': 'rewrite the computation in a way that', 'start': 124.719, 'duration': 3.361}, {'text': 'can be done in parallel it continues', 'start': 126.479, 'duration': 3.28}, {'text': 'this pattern until all computations are', 'start': 128.08, 'duration': 3.72}, {'text': 'done it then merges the result back into', 'start': 129.759, 'duration': 3.641}, {'text': 'whatever expression was returned from', 'start': 131.8, 'duration': 3.6}]
#     MainPoints(temp_transcript)

def MainPoints(transcript):
    '''Determines the key points of the video transcript'''
    keyPoints = []
    prompt = 'From the provided transcript data, choose the 7 most important values by context and return them in the format (start time, duration) as Python tuples. Do not include any other information other than the Python tuples.'
    final_prompt = prompt + '\n\n' + str(transcript)

    __ = load_dotenv(find_dotenv())
    client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
    model = "gpt-3.5-turbo"
    temperature = 0.3
    max_tokens = 250
    completion = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are summarizer. Given the transcript data of a Youtube video, choose the 7 most important values by context and return them in the format (start time, duration) as Python tuples. Do not include any other information other than the Python tuples."},
            {"role": "user", "content": final_prompt}
        ],
        temperature=temperature,
        max_tokens=max_tokens,
        )
    prompt_result = completion.choices[0].message.content

    print(prompt_result)
    return keyPoints

# Uncomment below for testing purposes
# if __name__ == '__main__':
#     main()